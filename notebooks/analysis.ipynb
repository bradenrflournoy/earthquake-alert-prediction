{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f0b64b",
   "metadata": {},
   "source": [
    "# Machine Learning Earthquake Alert Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7394522",
   "metadata": {},
   "source": [
    "## Introduction / Background\n",
    "\n",
    "Earthquake early warning systems are critical for reducing the impact of destructive seismic events. These systems provide time-sensitive alerts that give governments and communities a short but important window to prepare and respond. Traditional alert systems often rely on simple magnitude thresholds or basic seismic network rules, which can miss important context about how strongly an earthquake will be felt.\n",
    "\n",
    "Recent research has shown that using richer seismic features - such as shaking intensity, depth, and community-reported effects - can significantly improve the accuracy of early warning systems. Machine learning methods, including ensemble models and neural networks, have been successfully applied to earthquake records and have been shown to outperform simple threshold-based approaches by better capturing the complex relationships among seismic features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c09f9b",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Earthquakes often strike without warning and can cause severe damage with little time to react. Communities currently rely on early warning systems to issue alerts, but many of these systems depend on simple magnitude thresholds or limited seismic indicators. These approaches can lead to inaccurate alerts because they do not capture the full complexity of earthquake behavior.\n",
    "\n",
    "In this project, we aim to build machine learning models that classify earthquake alert levels into four categories - Green, Yellow, Orange, Red - using a richer set of seismic features:\n",
    "\n",
    "- Magnitude  \n",
    "- Depth  \n",
    "- CDI (community-reported intensity)  \n",
    "- MMI (instrumental intensity)  \n",
    "- Significance score (combined impact measure)\n",
    "\n",
    "Our goal is to design models that improve the accuracy and reliability of earthquake alerts compared to simple magnitude-based rules. We define several quantitative performance targets for the models:\n",
    "\n",
    "- Macro F1 ≥ 0.75  \n",
    "- Balanced Accuracy ≥ 0.80  \n",
    "- Macro ROC-AUC ≥ 0.85  \n",
    "- Brier Score ≤ 0.12  \n",
    "- Recall for the Red class ≥ 0.80 (most critical for life safety)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33be33d",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96dadf",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We use the *Earthquake Alert Prediction* dataset from Kaggle, which contains 1,300 earthquake records. Each record includes:\n",
    "\n",
    "- magnitude - event magnitude (Richter scale)  \n",
    "- depth - hypocenter depth in kilometers  \n",
    "- cdi - maximum reported community intensity  \n",
    "- mmi - maximum estimated instrumental intensity  \n",
    "- sig - “significance” score reflecting magnitude, intensity, reports, and impact  \n",
    "- alert - target alert level: Green, Yellow, Orange, or Red\n",
    "\n",
    "This dataset is already balanced across the four alert categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4d79e",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Our preprocessing pipeline standardizes and stabilizes the feature distributions before training:\n",
    "\n",
    "1. Distribution stabilization (PowerTransformer)  \n",
    "   - cdi and mmi are heavily skewed. We apply PowerTransformer to reduce skew and make these features more Gaussian-like, which helps linear models and distance-based methods learn better boundaries.\n",
    "\n",
    "2. Scale normalization (StandardScaler)  \n",
    "   - We standardize all features so that magnitude, depth, and significance share a common scale. This prevents any single feature from dominating the loss function.\n",
    "\n",
    "3. Class balance (RandomOverSampler)  \n",
    "   - Although our dataset is already balanced in counts, we demonstrate the use of RandomOverSampler and later include sampling inside model pipelines to make sure each alert level is treated fairly during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4556caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, PolynomialFeatures, LabelEncoder, label_binarize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix, f1_score, balanced_accuracy_score, roc_auc_score, brier_score_loss, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01129b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [\"../data/sample/dataset_sample.csv\",\n",
    "          \"../data/raw/earthquake_alert_balanced_dataset.csv\"]:\n",
    "    if Path(p).exists():\n",
    "        df = pd.read_csv(p)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Place sample in data/sample/ or full file in data/raw/\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['magnitude', 'depth', 'cdi', 'mmi', 'sig']]\n",
    "y = df['alert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dbe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "df[['cdi', 'mmi']] = pt.fit_transform(df[['cdi', 'mmi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84867086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "sns.histplot(df['cdi'], ax=axes[0], kde=True)\n",
    "axes[0].set_title('CDI after PowerTransform')\n",
    "sns.histplot(df['mmi'], ax=axes[1], kde=True)\n",
    "axes[1].set_title('MMI after PowerTransform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"../data/earthquake_alert_balanced_dataset.csv\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "sns.histplot(df_original['cdi'], ax=axes[0, 0], kde=True)\n",
    "axes[0, 0].set_title('CDI Before PowerTransform')\n",
    "\n",
    "sns.histplot(df_original['mmi'], ax=axes[0, 1], kde=True)\n",
    "axes[0, 1].set_title('MMI Before PowerTransform')\n",
    "\n",
    "sns.histplot(df['cdi'], ax=axes[1, 0], kde=True)\n",
    "axes[1, 0].set_title('CDI After PowerTransform')\n",
    "\n",
    "sns.histplot(df['mmi'], ax=axes[1, 1], kde=True)\n",
    "axes[1, 1].set_title('MMI After PowerTransform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_scaled, columns=X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0147f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "print(\"Before oversampling:\\n\", y.value_counts(), \"\\n\")\n",
    "print(\"After oversampling:\\n\", pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80353e",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9601ab",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Our baseline model is multinomial logistic regression, which assumes linear decision boundaries between alert levels. Logistic regression is:\n",
    "\n",
    "- Interpretable - coefficients directly show how each feature influences the log-odds of each alert category.\n",
    "- Efficient - fast to train and evaluate, making it a strong starting point before more complex methods.\n",
    "\n",
    "We use a pipeline that includes:\n",
    "- PowerTransformer on cdi and mmi\n",
    "- Optional polynomial features (degree 2) to capture pairwise interactions\n",
    "- Standardized features\n",
    "- Optional RandomOverSampler for balancing\n",
    "- GridSearchCV over regularization strength C and class_weight to optimize macro F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7476e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Testing split\n",
    "df = pd.read_csv(\"../data/earthquake_alert_balanced_dataset.csv\")\n",
    "N = df[['magnitude', 'depth', 'cdi', 'mmi', 'sig']]\n",
    "D = df['alert']\n",
    "\n",
    "NTrain, NTest, DTrain, DTest = train_test_split(\n",
    "    N, D, test_size=0.20, stratify=D, random_state=42\n",
    ")\n",
    "\n",
    "# Building the Pipeline\n",
    "features = ['magnitude', 'depth', 'cdi', 'mmi', 'sig']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"power\", PowerTransformer(), ['cdi', 'mmi']),\n",
    "        (\"pass\", 'passthrough', features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"poly\", \"passthrough\"),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"sampler\", \"passthrough\"),\n",
    "    (\"model\", LogisticRegression(solver=\"lbfgs\", max_iter=1000)),\n",
    "])\n",
    "\n",
    "# Training and Evaluating\n",
    "parameters = [{\n",
    "    \"poly\": [\"passthrough\", PolynomialFeatures(degree=2, include_bias=False)],\n",
    "    \"sampler\": [\"passthrough\", RandomOverSampler(random_state=42)],\n",
    "    \"model__C\": [0.25, 0.5, 1.0, 2.0, 4.0],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "}]\n",
    "\n",
    "cross = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=parameters,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cross,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(NTrain, DTrain)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(NTest)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(DTest, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c597cdab",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Our second model is a Random Forest classifier, which aggregates many decision trees trained on bootstrapped samples. Random Forests:\n",
    "\n",
    "- Capture non-linear relationships between features such as magnitude, depth, and significance.\n",
    "- Are robust to noise and reduce overfitting through averaging.\n",
    "\n",
    "We reuse the same preprocessing idea (PowerTransformer on cdi/mmi, StandardScaler on all features), then perform a grid search over:\n",
    "\n",
    "- Number of trees (n_estimators)\n",
    "- Maximum depth\n",
    "- Split and leaf sizes\n",
    "- Optional class_weight settings\n",
    "\n",
    "using 5-fold StratifiedKFold and GridSearchCV, optimizing macro F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/earthquake_alert_balanced_dataset.csv\")\n",
    "X = df[['magnitude', 'depth', 'cdi', 'mmi', 'sig']].copy()\n",
    "y = df['alert']\n",
    "\n",
    "# Power transform CDI/MMI, then scale all features\n",
    "pt = PowerTransformer()\n",
    "X[['cdi', 'mmi']] = pt.fit_transform(X[['cdi', 'mmi']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_rf = GridSearchCV(\n",
    "    rf,\n",
    "    params,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Best params:\", grid_rf.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89216585",
   "metadata": {},
   "source": [
    "#### Gradient Boosting (XGBoost)\n",
    "\n",
    "Our third model is a gradient boosting ensemble implemented with XGBoost. It builds many shallow trees sequentially, where each tree focuses on correcting errors made by previous trees. This approach is well-suited to structured tabular data and can model complex interactions between seismic features.\n",
    "\n",
    "We use the same preprocessing pipeline as logistic regression:\n",
    "- PowerTransformer on cdi and mmi\n",
    "- Polynomial features (degree 2) to model pairwise feature interactions\n",
    "- StandardScaler on all features\n",
    "- RandomOverSampler to keep alert classes balanced\n",
    "\n",
    "We train an XGBoost classifier with:\n",
    "- 200 trees\n",
    "- Maximum depth 4\n",
    "- Learning rate 0.1\n",
    "- multi:softprob objective for 4 alert classes\n",
    "\n",
    "and evaluate it on the same train-test split as the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df25ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels into integers for XGBoost\n",
    "le = LabelEncoder()\n",
    "DTrain_enc = le.fit_transform(DTrain)\n",
    "DTest_enc = le.transform(DTest)\n",
    "\n",
    "features = ['magnitude', 'depth', 'cdi', 'mmi', 'sig']\n",
    "\n",
    "preprocess_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"power\", PowerTransformer(), ['cdi', 'mmi']),\n",
    "        (\"pass\", \"passthrough\", features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "gb_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_gb),\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"sampler\", RandomOverSampler(random_state=42)),\n",
    "    (\"model\", XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=4,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        n_jobs=1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "gb_model.fit(NTrain, DTrain_enc)\n",
    "\n",
    "y_pred_enc = gb_model.predict(NTest)\n",
    "y_prob_gb = gb_model.predict_proba(NTest)\n",
    "\n",
    "classes_gb = le.classes_\n",
    "y_pred_gb = le.inverse_transform(y_pred_enc)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(DTest, y_pred_gb, target_names=classes_gb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b06a6",
   "metadata": {},
   "source": [
    "## Results & Discussion\n",
    "\n",
    "In this section, we evaluate our three models - Logistic Regression, Random Forest, and Gradient Boosting (XGBoost) - using quantitative metrics and visualizations. We then interpret each model’s performance in terms of our project goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c186af9",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05089a8f",
   "metadata": {},
   "source": [
    "#### Quantitative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab908fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_pred = best_model.predict(NTest)\n",
    "y_prob = best_model.predict_proba(NTest)\n",
    "classes = best_model.classes_\n",
    "print(\"Classes:\", list(classes))\n",
    "\n",
    "# Compute quantitative metrics\n",
    "macro_f1 = f1_score(DTest, y_pred, average='macro')\n",
    "balanced_acc = balanced_accuracy_score(DTest, y_pred)\n",
    "\n",
    "Y_true_ohe = pd.get_dummies(DTest).reindex(columns=classes, fill_value=0)\n",
    "macro_roc_auc = roc_auc_score(\n",
    "    Y_true_ohe, y_prob, multi_class='ovr', average='macro'\n",
    ")\n",
    "\n",
    "brier_macro = np.mean([\n",
    "    brier_score_loss((np.array(DTest) == c).astype(int), y_prob[:, i])\n",
    "    for i, c in enumerate(classes)\n",
    "])\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.3f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.3f}\")\n",
    "print(f\"Macro ROC-AUC: {macro_roc_auc:.3f}\")\n",
    "print(f\"Macro Brier (↓): {brier_macro:.3f}\")\n",
    "\n",
    "# Per-class performance table\n",
    "report = classification_report(\n",
    "    DTest, y_pred, target_names=classes, output_dict=True\n",
    ")\n",
    "pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201c73d",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5366d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix (Counts)\n",
    "cm = confusion_matrix(DTest, y_pred, labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm, display_labels=classes).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=False\n",
    ")\n",
    "ax.set_title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix (Normalized by row / recall)\n",
    "cm_norm = confusion_matrix(DTest, y_pred, labels=classes, normalize=\"true\")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm_norm, display_labels=classes).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=True\n",
    ")\n",
    "ax.set_title(\"Normalized Confusion Matrix (per-class recall)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d53c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves (One-vs-Rest)\n",
    "Y_true_bin = label_binarize(DTest, classes=classes)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(Y_true_bin[:, i], y_prob[:, i])\n",
    "    auc_i = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{c} (AUC = {auc_i:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curves - Logistic Regression (One-vs-Rest)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36445e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curves\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(classes):\n",
    "    precision, recall, _ = precision_recall_curve(Y_true_bin[:, i], y_prob[:, i])\n",
    "    ap = average_precision_score(Y_true_bin[:, i], y_prob[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{c} (AP = {ap:.2f})\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curves - Logistic Regression\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579c2ae",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "The Logistic Regression model achieved strong and balanced performance across the four alert levels. Based on the quantitative metrics:\n",
    "\n",
    "- Macro F1 Score (~0.80) shows that the model performs consistently across all classes, giving equal weight to each alert level (Green, Orange, Red).\n",
    "- Balanced Accuracy (~0.80) shows the model predicts each class fairly well, even when the number of samples per class differs.\n",
    "- Macro ROC-AUC (~0.93) shows the model can reliably distinguish between the different alert levels using probability scores.\n",
    "- Brier Score (~0.08) shows the model’s probability estimates are well-calibrated and not overconfident.\n",
    "\n",
    "The per-class metrics show that:\n",
    "- “Green” and “Orange” alerts are predicted with high precision (0.96 and 0.78 respectively), meaning few false alarms.\n",
    "- “Red” alerts have very high recall (0.92), meaning the model correctly catches most dangerous cases - this is ideal for an early-warning system where missing severe events is catastrophic.\n",
    "\n",
    "Overall, these metrics indicate the model captures meaningful patterns between seismic features (magnitude, depth, CDI, MMI, significance) and alert level while maintaining balanced predictive performance.\n",
    "\n",
    "The confusion matrix shows that most predictions fall along the diagonal, meaning the model correctly classifies the majority of earthquakes. A few misclassifications occur between Orange and Red alerts - this makes sense since these alert levels are adjacent in severity and share similar ranges of magnitude and intensity features. The normalized confusion matrix also shows that recall (the proportion of correctly identified alerts per class) remains high for all alert levels.\n",
    "\n",
    "The ROC curves show the tradeoff between the true positive rate and false positive rate for each alert class. Each curve lies well above the diagonal “random guess” line, showing the model’s ability to separate each alert level effectively. The area under the curves (AUC) is around 0.85 on average, which supports the earlier quantitative metrics.\n",
    "\n",
    "The precision-recall curves reinforce the same conclusion: the model maintains good precision for frequent classes like Green and Orange, while achieving strong recall for Red, which is the most safety-critical.\n",
    "\n",
    "Our group aims to build a machine learning model that is able to classify earthquake alert levels (Green, Yellow, Orange, Red) using a range of seismic features (magnitude, depth, CDI, MMI, and significance) instead of relying on only magnitude. As a baseline, we implemented a logistic regression model, following our plan in the project proposal. In our project proposal we set several key performance goals: a macro F1 score ≥ .75, a balanced accuracy ≥ .80, a macro ROC-AUC ≥ .85, a Brier score ≤ .12, and Red recall ≥ .80 with our most critical goal being the red recall due to it being most important to life safety.\n",
    "\n",
    "Our logistic regression model successfully achieved or exceeded most of these with values of:\n",
    "* Macro F1: 0.804\n",
    "* Macro ROC-AUC: 0.930\n",
    "* Macro Brier: 0.084\n",
    "\n",
    "Our model’s recall for the Red class was 0.923, which as seen in the confusion matrix means that this model correctly identifies 60 of 65 Red events in the test set which far surpasses our minimum safety target. However our balanced accuracy came in at 0.804, which is just at our .80 goal. Balanced accuracy is the average of all class’s recall with each individual class’s recall being:\n",
    "\n",
    "* Green Recall: 0.800  \n",
    "* Orange Recall: 0.800  \n",
    "* Red Recall: 0.923  \n",
    "* Yellow Recall: 0.692  \n",
    "\n",
    "While this model performed well on Red alerts and solid on the Green and Orange alerts, Yellow’s lower performance pulled the average down. The confusion matrix confirms this as many Yellow events were often misclassified as Green or Orange, suggesting that there is a complex relationship between the Green, Yellow, and Orange feature that this model struggles to show.\n",
    "\n",
    "Overall we believe that this model’s strong performance is due to our preprocessing pipeline. The PowerTransformer normalized and skewed cdi and mmi features, while the StandardScaler ensured that features like depth and sig which had large ranges didn’t dominate our model. The GridSearchCV also selected PolynomialFeatures(degree=2), which confirmed that interactions between features are critical for separating classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf21d0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2b96d",
   "metadata": {},
   "source": [
    "#### Quantitative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a972d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities for metrics/curves\n",
    "y_prob_rf = best_rf.predict_proba(X_test)\n",
    "classes_rf = best_rf.classes_\n",
    "print(\"Classes:\", list(classes_rf))\n",
    "\n",
    "macro_f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "balanced_acc_rf = balanced_accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "Y_true_ohe_rf = pd.get_dummies(y_test).reindex(columns=classes_rf, fill_value=0)\n",
    "macro_roc_auc_rf = roc_auc_score(\n",
    "    Y_true_ohe_rf, y_prob_rf, multi_class='ovr', average='macro'\n",
    ")\n",
    "\n",
    "brier_macro_rf = np.mean([\n",
    "    brier_score_loss((np.array(y_test) == c).astype(int), y_prob_rf[:, i])\n",
    "    for i, c in enumerate(classes_rf)\n",
    "])\n",
    "\n",
    "print(f\"Macro F1: {macro_f1_rf:.3f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_rf:.3f}\")\n",
    "print(f\"Macro ROC-AUC: {macro_roc_auc_rf:.3f}\")\n",
    "print(f\"Macro Brier (↓): {brier_macro_rf:.3f}\")\n",
    "\n",
    "report_rf = classification_report(\n",
    "    y_test, y_pred_rf, target_names=classes_rf, output_dict=True\n",
    ")\n",
    "pd.DataFrame(report_rf).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfa173",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix (Counts)\n",
    "labels_rf = classes_rf  # or sorted(y.unique())\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf, labels=labels_rf)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm_rf, display_labels=labels_rf).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=False\n",
    ")\n",
    "ax.set_title(\"Random Forest Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix (Normalized)\n",
    "cm_norm_rf = confusion_matrix(\n",
    "    y_test, y_pred_rf, labels=labels_rf, normalize=\"true\"\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm_norm_rf, display_labels=labels_rf).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=True\n",
    ")\n",
    "ax.set_title(\"Normalized Confusion Matrix - Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04efb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves (One-vs-Rest)\n",
    "Y_bin_rf = label_binarize(y_test, classes=labels_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(labels_rf):\n",
    "    fpr, tpr, _ = roc_curve(Y_bin_rf[:, i], y_prob_rf[:, i])\n",
    "    auc_i = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{c} (AUC = {auc_i:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curves - Random Forest (One-vs-Rest)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curves\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(labels_rf):\n",
    "    precision, recall, _ = precision_recall_curve(Y_bin_rf[:, i], y_prob_rf[:, i])\n",
    "    ap = average_precision_score(Y_bin_rf[:, i], y_prob_rf[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{c} (AP = {ap:.2f})\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curves - Random Forest\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0cd6f",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Our second model builds on our baseline by using a Random Forest classifier. Unlike logistic regression, which relies on linear decision boundaries, Random Forests can pick up more complex patterns between the seismic features (magnitude, depth, CDI, MMI, and significance). This made it a strong next step for our project since the relationships between alert levels are unlikely to be strictly linear.\n",
    "\n",
    "We used the same preprocessing steps as before - the PowerTransformer for CDI and MMI, and StandardScaler for all features. We then ran a 5-fold GridSearchCV over several parameters, including the number of trees, maximum depth, and split rules. The best model from this search used 100 trees with no limit on depth.\n",
    "\n",
    "The Random Forest achieved strong and balanced performance with the following overall results:\n",
    "* Accuracy: .923  \n",
    "* Macro F1: .924  \n",
    "* Macro Recall: .923  \n",
    "\n",
    "Per-class recall also showed strong performance across all alert levels:\n",
    "* Green Recall: .846  \n",
    "* Orange Recall: .954  \n",
    "* Red Recall: .969  \n",
    "* Yellow Recall: .923  \n",
    "\n",
    "These results show that the model identifies nearly all Red alerts, which remains our most important safety goal. It also performed especially well on Yellow and Orange alerts, suggesting that the nonlinear structure of Random Forests allows the model to pick up on subtle feature interactions that the logistic regression model struggled to capture.\n",
    "\n",
    "The confusion matrix supports this, with most predictions falling along the diagonal and relatively few alerts being confused with neighboring levels. Misclassifications that do occur tend to be between adjacent severity levels, which is expected given their shared feature ranges.\n",
    "\n",
    "Overall, the Random Forest results indicate that a more flexible model can better capture the relationships in our dataset. Its strong recall across all four alert classes, especially for Red and Yellow alerts, suggests that this approach may be better suited to representing the underlying structure of the seismic features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40517e9",
   "metadata": {},
   "source": [
    "### Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c6e6f",
   "metadata": {},
   "source": [
    "#### Quantitative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro metrics\n",
    "macro_f1_gb = f1_score(DTest, y_pred_gb, average='macro')\n",
    "balanced_acc_gb = balanced_accuracy_score(DTest, y_pred_gb)\n",
    "\n",
    "Y_true_ohe_gb = pd.get_dummies(DTest).reindex(columns=classes_gb, fill_value=0)\n",
    "macro_roc_auc_gb = roc_auc_score(\n",
    "    Y_true_ohe_gb, y_prob_gb, multi_class='ovr', average='macro'\n",
    ")\n",
    "\n",
    "macro_brier_gb = np.mean([\n",
    "    brier_score_loss((np.array(DTest) == c).astype(int), y_prob_gb[:, i])\n",
    "    for i, c in enumerate(classes_gb)\n",
    "])\n",
    "\n",
    "print(f\"Macro F1: {macro_f1_gb:.3f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_gb:.3f}\")\n",
    "print(f\"Macro ROC-AUC: {macro_roc_auc_gb:.3f}\")\n",
    "print(f\"Macro Brier (↓): {macro_brier_gb:.3f}\")\n",
    "\n",
    "# Per-class performance table\n",
    "report_gb = classification_report(\n",
    "    DTest, y_pred_gb, target_names=classes_gb, output_dict=True\n",
    ")\n",
    "pd.DataFrame(report_gb).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf9488",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix (Counts)\n",
    "cm_gb = confusion_matrix(DTest, y_pred_gb, labels=classes_gb)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm_gb, display_labels=classes_gb).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=False, values_format='d'\n",
    ")\n",
    "ax.set_title(\"Confusion Matrix - Gradient Boosting (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix (Normalized)\n",
    "cm_norm_gb = confusion_matrix(\n",
    "    DTest, y_pred_gb, labels=classes_gb, normalize=\"true\"\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(cm_norm_gb, display_labels=classes_gb).plot(\n",
    "    ax=ax, cmap=\"Blues\", colorbar=True\n",
    ")\n",
    "ax.set_title(\"Normalized Confusion Matrix - Gradient Boosting\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves (One-vs-Rest)\n",
    "Y_bin_gb = label_binarize(DTest, classes=classes_gb)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(classes_gb):\n",
    "    fpr, tpr, _ = roc_curve(Y_bin_gb[:, i], y_prob_gb[:, i])\n",
    "    auc_i = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{c} (AUC = {auc_i:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curves - Gradient Boosting (One-vs-Rest)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curves\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, c in enumerate(classes_gb):\n",
    "    precision, recall, _ = precision_recall_curve(Y_bin_gb[:, i], y_prob_gb[:, i])\n",
    "    ap = average_precision_score(Y_bin_gb[:, i], y_prob_gb[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{c} (AP = {ap:.2f})\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curves - Gradient Boosting\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d229474",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "With the XGBoost pipeline above:\n",
    "\n",
    "Macro F1: 0.923  \n",
    "Balanced accuracy: 0.923  \n",
    "Macro ROC-AUC: 0.986  \n",
    "Macro Brier: 0.031  \n",
    "Per-class recall: Green: 0.892, Orange: 0.969, Red: 0.923, Yellow: 0.908\n",
    "\n",
    "Gradient boosting:\n",
    "- Meets or exceeds all project targets (macro F1 ≥ .75, balanced accuracy ≥ .80, macro ROC-AUC ≥ .85, Brier ≤ .12, Red recall ≥ .80).\n",
    "- Maintains high recall for the critical Red alert level.\n",
    "- Produces strong classification performance for the Yellow alert level.\n",
    "- Achieves excellent probability calibration (Brier score ≈ 0.03).\n",
    "\n",
    "Gradient Boosting (XGBoost) Results\n",
    "\n",
    "To capture non-linear interactions between seismic features, we trained a gradient boosting model using XGBoost with the same preprocessing pipeline used throughout the project (PowerTransformer on CDI/MMI, StandardScaler, optional polynomial features, and RandomOverSampler for class balancing). The final model used 200 boosted trees with max depth 4 and learning rate 0.1.\n",
    "\n",
    "On the held-out test set, XGBoost achieved a macro F1 of 0.923, a balanced accuracy of 0.923, a macro ROC–AUC of 0.986, and a macro Brier score of 0.031. These values satisfy all of our predefined project goals.\n",
    "\n",
    "The per-class performance shows strong predictive ability across all alert levels. Recall for Green and Orange alerts reached 0.892 and 0.969, respectively, while Red recall remained high at 0.923. The Yellow class also showed strong performance, with recall of 0.908 and a corresponding F1 score near 0.89. These values indicate that the boosted trees are able to capture the complex boundaries between seismic patterns associated with different alert levels.\n",
    "\n",
    "The confusion matrix for XGBoost shows that most examples lie on the diagonal, with only a small number of cross-class confusions. The normalized matrix highlights the consistently high recall across all four alert levels. ROC and precision–recall curves for each class lie well above the random baseline, with areas under the ROC curves close to 1.0, indicating strong separability of the seismic patterns that correspond to each alert level.\n",
    "\n",
    "Overall, gradient boosting provides highly accurate and reliable earthquake alert classification across all severity levels. The model maintains high recall for the most severe Red alerts while also achieving strong performance for intermediate alert levels, making it a strong candidate for a practical early warning system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7da3b",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccf2d3-1b3b-4275-b48e-ceec6564835c",
   "metadata": {},
   "source": [
    "We were able to build three different Machine Learning models: linear regression, random forest, and gradient boosting. Based on the results we achieve, the gradient boosting model stood out as the best choice out of the three. This is because it provides the best balance of classification performance and reliability. The logistic repregression model was able to meet all of the minimum project targets but, because of its simplicity, it wasn't able to capture non-linear relationships. This, in turn, caused a low Yellow Recall score. When we utilized Random Forest, we were able to see an improvement from the linear regression model. This is because random forest was able to capture these non-linear interactions, achieving strong Macro F1 and Red Recall scores. However, the gradient boosting model was the most fitting out of the three since it scored higher on the Macro ROC-AUC and Brier scores. Based  on these metrics, we can determine that the gradient boosting model ensures the highest accuracy and most trustworthy probability estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36c3c6",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] T. T. Trugman, E. A. Casarotti, and P. M. Shearer, “Machine learning for earthquake early warning and ground motion prediction,” Seismological Research Letters, vol. 91, no. 5, pp. 2362–2376, 2020.\n",
    "\n",
    "[2] S. Mousavi and G. C. Beroza, “A machine-learning approach for earthquake magnitude estimation,” Geophysical Research Letters, vol. 47, no. 1, 2020.\n",
    "\n",
    "[3] X. Wang, Z. Wang, J. Wang, P. Miao, H. Dang, and Z. Li, “Machine learning based ground motion site amplification prediction,” Frontiers in Earth Science, vol. 11, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
